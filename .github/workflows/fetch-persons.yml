# ============================================================================= 
# Workflow: Fetch FCA Individual Records (Ad-hoc, chunked + throttled)
# =============================================================================
name: Fetch FCA Individual Records (Ad-hoc)

# Grant write so we can commit back to main
permissions:
  contents: write

# Manual trigger only, with throttling and chunking inputs
on:
  workflow_dispatch:
    inputs:
      chunks:
        description: 'Number of parallel chunks to split the IRN list into'
        required: true
        default: '5'
      limit:
        description: 'Max IRNs per chunk (blank = full run)'
        required: false
        default: ''

jobs:
  # ---------------------------------------------------------------------------
  # JOB 1: split
  #   - Read full IRN list, divide into parallel slices
  #   - Export both slice start offsets and total chunk count
  # ---------------------------------------------------------------------------
  split:
    runs-on: ubuntu-latest
    outputs:
      chunk_list: ${{ steps.set-chunks.outputs.chunk_list }}
      chunk_count: ${{ steps.set-chunks.outputs.chunk_count }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v3
        # Ensures fca-dashboard/data/fca_individuals_by_firm.json is present

      - id: set-chunks
        name: Compute chunk start indices
        run: |
          # 1. Load total IRNs from the firmâ†’individuals map
          TOTAL=$(jq 'length | floor' fca-dashboard/data/fca_individuals_by_firm.json)

          # 2. Desired parallelism
          CHUNKS=${{ github.event.inputs.chunks }}

          # 3. Build JSON array of start indices via Python one-liner
          python3 -c "import math, json; total=int('$TOTAL'); n=int('$CHUNKS'); size=math.ceil(total/n); print(json.dumps(list(range(0,total,size))))" \
            > indices.json

          # 4. Expose start offsets for matrix
          echo "chunk_list=$(cat indices.json)" >> $GITHUB_OUTPUT

          # 5. Expose actual number of chunks created
          echo "chunk_count=$(jq 'length' indices.json)" >> $GITHUB_OUTPUT

  # ---------------------------------------------------------------------------
  # JOB 2: fetch
  #   - Parallel workers: each pulls one slice of IRNs
  #   - Throttles API calls to floor(50/chunk_count) per 10s per worker
  # ---------------------------------------------------------------------------
  fetch:
    needs: split
    runs-on: ubuntu-latest
    strategy:
      matrix:
        start: ${{ fromJson(needs.split.outputs.chunk_list) }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Fetch persons chunk (throttled)
        env:
          FCA_API_EMAIL: ${{ secrets.FCA_API_EMAIL }}
          FCA_API_KEY:   ${{ secrets.FCA_API_KEY }}
        run: |
          # 1. This workerâ€™s slice offset & total number of chunks
          OFFSET=${{ matrix.start }}
          COUNT=${{ needs.split.outputs.chunk_count }}

          # 2. Compute per-worker rate limits (floor(50/COUNT) calls per 10s)
          RL_MAX_CALLS=$((50 / COUNT))
          RL_WINDOW_S=10
          echo "ðŸ”¢ Each worker: up to $RL_MAX_CALLS calls per $RL_WINDOW_S seconds"

          # 3. Export for RateLimiter in Python script
          export RL_MAX_CALLS RL_WINDOW_S

          # 4. Pass --limit for test runs, if provided
          if [ -n "${{ github.event.inputs.limit }}" ]; then
            LIMIT="--limit ${{ github.event.inputs.limit }}"
          else
            LIMIT=""
          fi

          # 5. Prepare output folder for this chunk
          mkdir -p "chunks/persons-chunk-${OFFSET}"

          # 6. Invoke chunked fetch script (writes IRNâ†’record JSON)
          python3 fca-dashboard/scripts/fetch_persons.py \
            --offset "$OFFSET" $LIMIT \
            --output "chunks/persons-chunk-${OFFSET}/fca_persons.json"

      - name: Upload chunk artifact
        uses: actions/upload-artifact@v4
        with:
          name: persons-chunk-${{ matrix.start }}
          path: chunks/persons-chunk-${{ matrix.start }}/fca_persons.json

  # ---------------------------------------------------------------------------
  # JOB 3: merge
  #   - Download all chunk artifacts
  #   - Merge into single UI JSON under docs/
  # ---------------------------------------------------------------------------
  merge:
    needs: fetch
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Download all chunk artifacts
        uses: actions/download-artifact@v4
        with:
          path: chunks

      - name: Merge into UI data folder
        run: |
          # 1. Ensure target folder exists
          mkdir -p docs/fca-dashboard/data

          # 2. Run merge script to combine all partial JSONs
          python3 fca-dashboard/scripts/merge_persons.py \
            chunks docs/fca-dashboard/data/fca_persons.json

      - name: Commit & push merged result
        run: |
          # Configure bot identity
          git config user.name "github-actions[bot]"
          git config user.email "actions@github.com"

          # Stage the final JSON in docs/
          git add docs/fca-dashboard/data/fca_persons.json

          # Commit if content changed vs. HEAD
          git diff --cached --quiet || \
            git commit -m "chore(fca): merge individual records into docs"

          # Push back to main
          git push origin HEAD:main
